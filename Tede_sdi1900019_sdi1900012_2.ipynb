{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Αποστολάτος Ιωάννης sdi1900012 \\\\\n",
        "Βασιλείου Ρηγίνος sdi1900019"
      ],
      "metadata": {
        "id": "hb40U3N-rtcH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSoERQB4HtPq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/MyDrive/books_1.Best_Books_Ever.csv')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "id4aAkv8KV0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove nan"
      ],
      "metadata": {
        "id": "TkRoTyJFKvrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_dropna = ['bookId', 'ratingsByStars', \"description\", \"genres\", \"publishDate\"]\n",
        "df = df.dropna(subset=columns_to_dropna)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "dXi25qUWKvJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"ratingsByStars\"].head(10)\n",
        "type(df[\"ratingsByStars\"][1])\n",
        "\n",
        "df[\"ratingsByStars\"][1]"
      ],
      "metadata": {
        "id": "hrqp65PYLHz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate ratings"
      ],
      "metadata": {
        "id": "N1-q3RQHLn-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['ratingStar5', 'ratingStar4', 'ratingStar3', 'ratingStar2', 'ratingStar1']] = df['ratingsByStars'].str.split(',', expand=True)\n",
        "\n",
        "# keep numerical values\n",
        "columns_to_convert = ['ratingStar5', 'ratingStar4', 'ratingStar3', 'ratingStar2', 'ratingStar1']\n",
        "\n",
        "for column in columns_to_convert:\n",
        "    df[column] = df[column].str.replace(r'\\D', '')\n",
        "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "BURBRxSaLmic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['genres'].head(5)"
      ],
      "metadata": {
        "id": "LvNgq0AeN8pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform genres to genreSingle"
      ],
      "metadata": {
        "id": "EiBkJfQ1sJgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['genreSingle'] = df['genres'].str.split(',').str[0].str.strip()\n",
        "df['genreSingle'] = df['genreSingle'].str.replace(r'\\[', '', regex=True)\n",
        "\n",
        "df['genreSingle'].head(5)"
      ],
      "metadata": {
        "id": "moUQXz9cSckk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['publishDate']"
      ],
      "metadata": {
        "id": "tVfKXfA9Vj4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform publishDate column to the same date format"
      ],
      "metadata": {
        "id": "w9hHIA8msUvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a regular expression pattern to match valid date strings\n",
        "date_pattern = r'(\\b\\d{1,2}/\\d{1,2}/\\d{2}\\b)|(\\b[A-Za-z]+\\s\\d{1,2}(?:st|nd|rd|th)?\\s\\d{2,4}\\b)|(\\b[A-Za-z]+\\s\\d{4}\\b)|(\\bHalloween\\s\\d{4}\\b)'\n",
        "\n",
        "# Extract the valid date strings based on the pattern\n",
        "extracted_dates = df['publishDate'].str.extract(date_pattern)\n",
        "\n",
        "extracted_dates[1] = extracted_dates[1].str.replace(r'\\bHalloween\\b', 'October')\n",
        "\n",
        "# Convert the extracted dates to datetime\n",
        "converted_dates = pd.to_datetime(extracted_dates[0].fillna('') + extracted_dates[1].fillna('') + extracted_dates[2].fillna(''), infer_datetime_format=True, errors='coerce')\n",
        "\n",
        "# Assign the converted dates to the original column\n",
        "df['publishDate'] = converted_dates\n",
        "\n",
        "df['publishDate'].head(10)"
      ],
      "metadata": {
        "id": "r88o0QuRVVxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create publishYear column"
      ],
      "metadata": {
        "id": "Kds2eAyYsgF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['publishYear'] = df['publishDate'].dt.year"
      ],
      "metadata": {
        "id": "QBQS96toYUTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['publishYear'] = df['publishYear'].fillna(0).astype(int)\n",
        "\n",
        "df['publishYear']"
      ],
      "metadata": {
        "id": "GmOQ-u59ZI8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ποιά είναι τα 10 βιβλία με τις περισσότερες σελίδες."
      ],
      "metadata": {
        "id": "ltf4w2D9bbor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['pages'] = pd.to_numeric(df['pages'], errors='coerce')\n",
        "\n",
        "books = df.nlargest(10, 'pages')\n",
        "\n",
        "for index in books.index:\n",
        "    print(df['title'][index])\n",
        "    print(df['pages'][index])"
      ],
      "metadata": {
        "id": "Im2yHtX0Z-xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ποιά είναι τα 10 βιβλία με τα περισσότερα 5-αστέρια"
      ],
      "metadata": {
        "id": "XWBkNzBTbdIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df[df['ratingStar5'] > 10000]\n",
        "\n",
        "# Get the 10 highest values of 'ratingStar5' from the filtered DataFrame\n",
        "books = filtered_df.nlargest(10, 'ratingStar5')\n",
        "\n",
        "for index in books.index:\n",
        "    print(df['title'][index])\n",
        "    print(df['ratingStar5'][index])"
      ],
      "metadata": {
        "id": "9UOtxN1Ibc0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ποιοι είναι οι 10 συγγραφεις με τα περισσότερα βιβλία"
      ],
      "metadata": {
        "id": "V3vBFN0KeOmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_authors = df['author'].value_counts().head(10)\n",
        "\n",
        "top_10_authors"
      ],
      "metadata": {
        "id": "iSMiSkkVeR2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ποιοι είναι οι 10 συγγραφείς με τις περισσότερες κριτικές"
      ],
      "metadata": {
        "id": "HHWT1t-HcxIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(df['numRatings'][1])\n",
        "\n",
        "def sumRatings(x, authors):\n",
        "    author_ratings = df.loc[df['author'] == x, 'numRatings'].sum()\n",
        "    authors[x] = author_ratings\n",
        "\n",
        "    return author_ratings"
      ],
      "metadata": {
        "id": "fd1esvTif2_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = dict()\n",
        "df['author'].apply(lambda x: sumRatings(x, authors))\n",
        "\n",
        "highest_10 = sorted(authors.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "highest_10"
      ],
      "metadata": {
        "id": "qfOSmeAIcx0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ποιές είναι οι πιο συχνές γλώσσες που έχουν γραφτεί τα βιβλία στα δεδομένα σας"
      ],
      "metadata": {
        "id": "nkXLz4_ljw_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "common_lang = df['language'].value_counts()\n",
        "\n",
        "common_lang.plot(kind=\"bar\")\n",
        "plt.xlabel(\"languages\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.title(\"Most Common Languages\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v1RRcaLcjwir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Recomendation System"
      ],
      "metadata": {
        "id": "LxztVldNlAu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "ObjuqdvpmQZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Δημιουργία νέου dataframe"
      ],
      "metadata": {
        "id": "A-RXnFLrtVIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recomender_df = df[df['language'] == 'English']\n",
        "recomender_df = recomender_df[['bookId', 'description']]\n",
        "\n",
        "recomender_df"
      ],
      "metadata": {
        "id": "0aea_4kwlDw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recomender_df = recomender_df[:10000]"
      ],
      "metadata": {
        "id": "Tj8-mRcysCIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess για το description"
      ],
      "metadata": {
        "id": "eaeGjqzb2gq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(desc):\n",
        "  desc = str(desc)\n",
        "  desc = desc.lower()\n",
        "  desc = re.sub(r'[^a-zA-Z]', ' ', desc)\n",
        "\n",
        "  tokens = nltk.word_tokenize(desc)\n",
        "  tokens = [word for word in tokens if word not in stop_words]\n",
        "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "def preprocess_df(df, column_name):\n",
        "  df[column_name] = df[column_name].apply(preprocess)\n",
        "  return df\n",
        "\n",
        "recomender_df = preprocess_df(recomender_df, 'description')\n",
        "\n",
        "recomender_df.head(10)"
      ],
      "metadata": {
        "id": "aUhuJqYA2jFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=0, analyzer = \"word\")\n",
        "tfidf_matrix = vectorizer.fit_transform(recomender_df['description'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "cosine_sim"
      ],
      "metadata": {
        "id": "Q98HTd6BncJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate similar books and store in dictionary\n",
        "num_similar = 100\n",
        "similar_books = {}\n",
        "\n",
        "num_books = len(recomender_df)\n",
        "\n",
        "for i in range(num_books):\n",
        "    similarities = cosine_sim[i]\n",
        "    similar_books[i] = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)[:num_similar]\n",
        "\n",
        "# Prediction function\n",
        "def get_similar_books(book_id, N):\n",
        "    # Find the index of the book with the given book_id\n",
        "    book_index = recomender_df[recomender_df['bookId'] == book_id].index[0]\n",
        "\n",
        "    similar_books_list = similar_books[book_index][:N]\n",
        "    book_data = [(recomender_df.iloc[book[0]]['bookId'], book[1]) for book in similar_books_list]\n",
        "    return book_data\n",
        "\n",
        "def print_similar_books(recommended_books, book_id, N):\n",
        "    # Find the index of the book with the given book_id\n",
        "    book_index = recomender_df[recomender_df['bookId'] == book_id].index[0]\n",
        "\n",
        "    print(\"Recommending\", N, \"books similar to\", df.loc[book_index, 'title'])\n",
        "    print(\"---------------------------------------------------------------------------------------\\n\")\n",
        "    for recommended_book_id, similarity_score in recommended_books:\n",
        "        book_index = recomender_df[recomender_df['bookId'] == recommended_book_id].index[0]\n",
        "        title = df.loc[book_index, 'title']\n",
        "        print(\"Recommended:\", title.upper())\n",
        "        print(\"Description:\", df.loc[book_index, 'description'])\n",
        "        print(\"(score:\",similarity_score,\")\")\n",
        "        print()\n",
        "\n",
        "# Example usage\n",
        "book_id = \"2.Harry_Potter_and_the_Order_of_the_Phoenix\"  # Example book ID\n",
        "N = 10  # Number of similar books to retrieve\n",
        "\n",
        "recommended_books = get_similar_books(book_id, N)\n",
        "\n",
        "print_similar_books(recommended_books, book_id, N)"
      ],
      "metadata": {
        "id": "2acqbbfFjVuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classification"
      ],
      "metadata": {
        "id": "k3_XErXCsGWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_genres = df['genreSingle'].value_counts().head(10)\n",
        "\n",
        "top_10_genres = top_10_genres.index.tolist()\n",
        "\n",
        "classification_df =  df[['bookId', 'description', 'genreSingle']]\n",
        "\n",
        "classification_df = classification_df[classification_df['genreSingle'].isin(top_10_genres)]\n",
        "\n",
        "classification_df"
      ],
      "metadata": {
        "id": "6p2KsVpYsJKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_df = preprocess_df(classification_df, 'description')\n",
        "\n",
        "classification_df"
      ],
      "metadata": {
        "id": "dIIZUElHu-6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_df = classification_df[:10000]"
      ],
      "metadata": {
        "id": "cJQ30UiZvtVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "tokenized_desc = classification_df['description'].apply(lambda x: x.split()) # tokenizing\n",
        "model_w2v = Word2Vec(\n",
        "                  tokenized_desc,\n",
        "                  vector_size=200, # desired no. of features/independent variables\n",
        "                  window=5, # context window size\n",
        "                  min_count=2,\n",
        "                  sg = 1, # 1 for skip-gram model\n",
        "                  hs = 0,\n",
        "                  negative = 10, # for negative sampling\n",
        "                  workers= 4, # no.of cores\n",
        "                  seed = 34)\n",
        "model_w2v.train(tokenized_desc, total_examples= len(classification_df['description']), epochs=20)"
      ],
      "metadata": {
        "id": "ZhIrKt9YwNsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v.wv.most_similar(positive=\"red\")"
      ],
      "metadata": {
        "id": "iUkzDCxtyRUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_description_vector(description):\n",
        "    # Tokenize the description\n",
        "    tokens = description.split()\n",
        "\n",
        "    # Initialize an empty list to store the word vectors\n",
        "    word_vectors = []\n",
        "\n",
        "    # Retrieve word vectors for each token\n",
        "    for token in tokens:\n",
        "        if token in model_w2v.wv:\n",
        "            word_vector = model_w2v.wv[token]\n",
        "            word_vectors.append(word_vector)\n",
        "\n",
        "    # Check if any word vectors were found\n",
        "    if len(word_vectors) > 0:\n",
        "        # Compute the average of word vectors\n",
        "        description_vector = np.mean(word_vectors, axis=0)\n",
        "    else:\n",
        "        # If no word vectors were found, return a zero vector\n",
        "        description_vector = np.zeros(model_w2v.vector_size)\n",
        "\n",
        "    return description_vector\n",
        "\n",
        "classification_df['desc_vector'] = classification_df['description'].apply(lambda x: get_description_vector(x))\n",
        "\n",
        "classification_df['desc_vector']"
      ],
      "metadata": {
        "id": "3BiAEaYMzsWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Αποθηκεύουμε το DataFrame σε ένα αρχείο .pkl\n",
        "with open('features.pkl', 'wb') as file:\n",
        "    pickle.dump(classification_df['desc_vector'], file)\n",
        "\n",
        "# Φορτώνουμε το DataFrame από το αρχείο .pkl\n",
        "with open('features.pkl', 'rb') as file:\n",
        "    loaded_features = pickle.load(file)\n",
        "\n",
        "# Τώρα το φορτωμένο DataFrame είναι έτοιμο για χρήση\n",
        "print(type(loaded_features))"
      ],
      "metadata": {
        "id": "88I5_9LN01xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Naive Bayes"
      ],
      "metadata": {
        "id": "6OMXDKRZ-xUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "\n",
        "scoring = {\n",
        "    'precision': make_scorer(precision_score, average='macro', zero_division=0),\n",
        "    'recall': make_scorer(recall_score, average='macro', zero_division=0),\n",
        "    'f1_score': make_scorer(f1_score, average='macro', zero_division=0),\n",
        "    'accuracy': 'accuracy'\n",
        "}\n",
        "\n",
        "X = np.array(classification_df['desc_vector'].tolist())\n",
        "Y = classification_df['genreSingle']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
        "\n",
        "model = GaussianNB().fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "scores = cross_validate(model, X, Y, cv=kfold, scoring=scoring, error_score='raise', return_train_score=False)\n",
        "\n",
        "precision_avg = scores['test_precision'].mean()\n",
        "recall_avg = scores['test_recall'].mean()\n",
        "f1_score_avg = scores['test_f1_score'].mean()\n",
        "accuracy_avg = scores['test_accuracy'].mean()\n",
        "\n",
        "print(\"Precision (macro average):\", precision_avg)\n",
        "print(\"Recall (macro average):\", recall_avg)\n",
        "print(\"F1-score (macro average):\", f1_score_avg)\n",
        "print(\"Accuracy:\", accuracy_avg)"
      ],
      "metadata": {
        "id": "kCjk-9-J1w-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b2358b-6176-412c-bcb0-317d64e74928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (macro average): 0.40870000000000006\n",
            "Recall (macro average): 0.40870000000000006\n",
            "F1-score (macro average): 0.40870000000000006\n",
            "Accuracy: 0.40870000000000006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{array}{|c|c|c|c|c|c|}\n",
        "    \\hline\n",
        "    df size & average & precision & recall & f1-score & accuracy \\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' & 0.5221295316689785 & 0.4063 & 0.3634986971327451 & 0.4063 \\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.4218160714061529 & 0.4308436912496119\n",
        "    & 0.3541748177783423 & 0.4063 \\\\\n",
        "    \\hline\n",
        "    10000 & 'micro' & 0.4063 & 0.4063\n",
        "    & 0.40630000000000005 & 0.4063 \\\\\n",
        "    \\hline\n",
        "\\end{array}"
      ],
      "metadata": {
        "id": "RB8hL4Q46cCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVM's"
      ],
      "metadata": {
        "id": "4zmdUa19-zwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "X = np.array(classification_df['desc_vector'].tolist())\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, classification_df['genreSingle'], test_size = 0.2, random_state=42)\n",
        "\n",
        "model = svm.SVC(C=1, kernel='poly', gamma='auto').fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "scores = cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
        "\n",
        "precision_avg = scores['test_precision'].mean()\n",
        "recall_avg = scores['test_recall'].mean()\n",
        "f1_score_avg = scores['test_f1_score'].mean()\n",
        "accuracy_avg = scores['test_accuracy'].mean()\n",
        "\n",
        "print(\"Precision (macro average):\", precision_avg)\n",
        "print(\"Recall (macro average):\", recall_avg)\n",
        "print(\"F1-score (macro average):\", f1_score_avg)\n",
        "print(\"Accuracy:\", accuracy_avg)"
      ],
      "metadata": {
        "id": "miYEp2S3-12C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa86e96-96bb-41d9-9d65-5a8549949b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (macro average): 0.23850000000000002\n",
            "Recall (macro average): 0.23850000000000002\n",
            "F1-score (macro average): 0.23850000000000002\n",
            "Accuracy: 0.23850000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{array}{|c|c|c|c|c|c|}\n",
        "    \\hline\n",
        "    df size & average & precision & recall & f1-score & accuracy & C & kernel & gamma\\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' & 0.6792768753852335 & 0.6678000000000001 & 0.6522683797259655 & 0.6678000000000001 & 1.0 & 'rbf' & 'scale'\\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.6802518874619129 & 0.5480011940702822\n",
        "    & 0.5771918774220145 & 0.6678000000000001 & 1.0 & 'rbf' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'micro' & 0.6678000000000001 & 0.6678000000000001\n",
        "    & 0.6678000000000001 & 0.6678000000000001 & 1.0 & 'rbf' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'micro' & 0.6604000000000001 & 0.6604000000000001\n",
        "    & 0.6604000000000001 & 0.6604000000000001 & 0.75 & 'rbf' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.6751716801177108 & 0.5316729158471419\n",
        "    & 0.5649371966852927 & 0.6622 & 0.75 & 'rbf' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' & 0.6751551578609265 & 0.6622\n",
        "    & 0.6443373258912279 & 0.6622 & 0.75 & 'rbf' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' & 0.6662915959345186 & 0.6504000000000001\n",
        "    & 0.6288118114319659 & 0.6504000000000001 & 0.5 & 'rbf' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.6514537439985582 & 0.5072699986293276\n",
        "    & 0.5429834320856206 & 0.6504000000000001 & 0.5 & 'rbf' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'micro' & 0.6504000000000001 & 0.6504000000000001\n",
        "    & 0.6504000000000001 & 0.6504000000000001 & 0.5 & 'rbf' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'micro' & 0.6623000000000001 & 0.6623000000000001\n",
        "    & 0.6623000000000001 & 0.6623000000000001 & 1.0 & 'linear' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.6432803569752201 & 0.5545233959751643\n",
        "    & 0.5761151198228849 & 0.6623000000000001 & 1.0 & 'linear' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' & 0.6613705693951196 & 0.6623000000000001\n",
        "    & 0.648813333483055 & 0.6623000000000001 & 1.0 & 'linear' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' & 0.6813601550398586 & 0.6712\n",
        "    & 0.6559179816836453 & 0.6712 & 1.0 & 'poly' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.6813601550398586 & 0.6712\n",
        "    & 0.6559179816836453 & 0.6712 & 1.0 & 'poly' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'micro' & 0.6712 & 0.6712\n",
        "    & 0.6712 & 0.6712 & 1.0 & 'poly' & 'scale' \\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.23850000000000002 & 0.23850000000000002\n",
        "    & 0.23850000000000002 & 0.23850000000000002 & 1.0 & 'poly' & 'auto' \\\\\n",
        "    \\hline\n",
        "\\end{array}"
      ],
      "metadata": {
        "id": "_lBy5vwU9Xuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forests"
      ],
      "metadata": {
        "id": "p96Pq8B4B8Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(max_depth=2, random_state=42).fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "scores = cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
        "\n",
        "precision_avg = scores['test_precision'].mean()\n",
        "recall_avg = scores['test_recall'].mean()\n",
        "f1_score_avg = scores['test_f1_score'].mean()\n",
        "accuracy_avg = scores['test_accuracy'].mean()\n",
        "\n",
        "print(\"Precision (macro average):\", precision_avg)\n",
        "print(\"Recall (macro average):\", recall_avg)\n",
        "print(\"F1-score (macro average):\", f1_score_avg)\n",
        "print(\"Accuracy:\", accuracy_avg)"
      ],
      "metadata": {
        "id": "3stNFO-HB-y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4958d5-cbe9-4293-f3c7-acffedbd31dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (macro average): 0.1413949130687595\n",
            "Recall (macro average): 0.1808072001832111\n",
            "F1-score (macro average): 0.12181192726852456\n",
            "Accuracy: 0.41059999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{array}{|c|c|c|c|c|c|}\n",
        "    \\hline\n",
        "    df size & average & precision & recall & f1-score & accuracy & max depth\\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.13771582222147544 & 0.17914135482818644 & 0.11823657431961032 &0.4088 &2\\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' &  0.26671859036419165 & 0.4088 & 0.26626648742766806 &0.4088 &2\\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.6670470797699398 & 0.3358458169106126 & 0.35071046743569967 &0.5408999999999999 & 10\\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' & 0.6348077201508254 &  0.5408999999999999 & 0.47732582453726813 &0.5408999999999999 & 10\\\\\n",
        "    \\hline\n",
        "    10000 & 'macro' & 0.6667965072594207 & 0.3901888622877353 & 0.4234875195464142 &0.5742 & 50\\\\\n",
        "    \\hline\n",
        "    10000 & 'weighted' & 0.6368988799830719 & 0.5742 & 0.5295475319899082 &0.5742 & 50\\\\\n",
        "    \\hline\n",
        "\\end{array}"
      ],
      "metadata": {
        "id": "eepDjAAJoCj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bonus"
      ],
      "metadata": {
        "id": "XHHhdhwzCZlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import time\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "jlwZCr42Cbjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DIR_PATH = \"drive/MyDrive/\"\n",
        "\n",
        "def get_books_cover(DIR_PATH, books, bookIds):\n",
        "        \"\"\"\n",
        "        Retrieves books covers to a img/ directory\n",
        "        Will work on existing books class attribute, so a GoodReads list should be scraped or a books list loaded\n",
        "        (csv_to_books) before use.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        img_dir = \"img\"\n",
        "        check_folder = os.path.isdir(img_dir)\n",
        "\n",
        "        # If folder doesn't exist, then create it.\n",
        "        if not check_folder:\n",
        "            os.makedirs( DIR_PATH + img_dir, exist_ok=True)\n",
        "            print(\"Creating folder: \", img_dir)\n",
        "\n",
        "        else:\n",
        "            print(img_dir, \"folder already exists, saving images to folder.\")\n",
        "\n",
        "        counter = 0\n",
        "        # Download covers\n",
        "        for (book, bookId) in zip(books, bookIds):\n",
        "                urllib.request.urlretrieve(\n",
        "                     book, DIR_PATH + \"img/\" + bookId  + \".jpg\"\n",
        "                )\n",
        "                # Set a respectful wait time\n",
        "                time.sleep(2)\n",
        "                if counter == 700:\n",
        "                  break\n",
        "                counter += 1"
      ],
      "metadata": {
        "id": "H6B--sEGC80u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = DIR_PATH + \"books_1.Best_Books_Ever.csv\"\n",
        "\n",
        "finalbooks = pd.read_csv(file)\n",
        "\n",
        "finalbooks['coverImg'].head()\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "hjPBKWVADGtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = DIR_PATH + 'img/'  # Specify the directory path\n",
        "\n",
        "file_count = len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
        "\n",
        "print(f\"Number of files in '{directory}': {file_count}\")"
      ],
      "metadata": {
        "id": "RidbpHAQMgRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_dropna = ['coverImg', 'bookId']\n",
        "finalbooks = finalbooks.dropna(subset=columns_to_dropna)\n",
        "\n",
        "images = finalbooks['coverImg']\n",
        "Ids = finalbooks['bookId']\n",
        "\n",
        "images = images[:700]\n",
        "Ids = Ids[:700]\n",
        "\n",
        "if file_count != 701:\n",
        "  get_books_cover(DIR_PATH, images, Ids)"
      ],
      "metadata": {
        "id": "3iyOif8CDcte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Βήμα 2"
      ],
      "metadata": {
        "id": "8bYYde185l-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "\n",
        "folder_path = directory\n",
        "\n",
        "# Αρχικοποίηση του DataFrame\n",
        "histogram_df = pd.DataFrame(columns=['id', 'histogram_b', 'histogram_g', 'histogram_r', 'histogram'])\n",
        "\n",
        "# Παράμετροι για τον υπολογισμό του ιστογράμματος\n",
        "channels = [0, 1, 2]\n",
        "bins = 32\n",
        "hist_range = [0, 256]\n",
        "id = 0\n",
        "counter = 0\n",
        "test_images = []\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    # Check if the file is an image file (you can modify this condition based on your specific requirements)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "      image_path = os.path.join(folder_path, filename)\n",
        "      if counter < 650:\n",
        "        image = cv.imread(image_path)\n",
        "\n",
        "        hist_b = cv.calcHist([image], [channels[0]], None, [bins], hist_range)\n",
        "        hist_g = cv.calcHist([image], [channels[1]], None, [bins], hist_range)\n",
        "        hist_r = cv.calcHist([image], [channels[2]], None, [bins], hist_range)\n",
        "\n",
        "        hist_vector = np.concatenate((hist_b, hist_g, hist_r)).flatten()\n",
        "\n",
        "        histogram_df.loc[id] = [id, hist_vector[0:bins], hist_vector[bins:2*bins], hist_vector[2*bins:], hist_vector]\n",
        "      else:\n",
        "        test_images.append(image_path)\n",
        "\n",
        "      id += 1\n",
        "      counter += 1\n",
        "\n",
        "histogram_df['id'] = Ids[:649]\n",
        "histogram_df"
      ],
      "metadata": {
        "id": "A243vRFT43-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 3"
      ],
      "metadata": {
        "id": "JDdz8pjAOcAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = test_images[0]\n",
        "\n",
        "image = cv.imread(image_path)\n",
        "\n",
        "hist_b = cv.calcHist([image], [channels[0]], None, [bins], hist_range)\n",
        "hist_g = cv.calcHist([image], [channels[1]], None, [bins], hist_range)\n",
        "hist_r = cv.calcHist([image], [channels[2]], None, [bins], hist_range)\n",
        "\n",
        "hist_vector = np.concatenate((hist_b, hist_g, hist_r)).flatten()\n",
        "\n",
        "test_vector = hist_vector"
      ],
      "metadata": {
        "id": "rP4IIysG6jld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 4"
      ],
      "metadata": {
        "id": "q8sWvv-XQjUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y8GlJx5CQlNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarity(hist1, hist2, metric):\n",
        "    if metric == 'euclidean':\n",
        "        return euclidean(hist1, hist2)\n",
        "    elif metric == 'cosine':\n",
        "        return 1 - cosine_similarity(hist1.reshape(1, -1), hist2.reshape(1, -1))\n",
        "    else:\n",
        "        raise ValueError('Invalid metric. Choose either \"euclidean\" or \"cosine\".')\n"
      ],
      "metadata": {
        "id": "NwyvPdFuQnrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_images(query_hist, histograms, metric, num_images=4):\n",
        "    similarities = []\n",
        "    for hist in histograms:\n",
        "        similarity = calculate_similarity(query_hist, hist, metric)\n",
        "        similarities.append(similarity)\n",
        "    indices = np.argsort(similarities)[:num_images]\n",
        "    return indices\n"
      ],
      "metadata": {
        "id": "1AxSjMNLQqPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Try it on test image"
      ],
      "metadata": {
        "id": "-Xw3JsFJTalL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_hist = test_vector\n",
        "\n",
        "closest_indices = find_closest_images(query_hist, histogram_df['histogram'], 'euclidean', num_images=4)"
      ],
      "metadata": {
        "id": "AT8ZGft5QsQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "test = test_images[0]\n",
        "\n",
        "print(\"Closest images to : \" + test)\n",
        "\n",
        "if os.path.exists(test):\n",
        "      image = cv.imread(test)\n",
        "      if image is not None:\n",
        "          image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "          plt.subplot(1, 4, 4)\n",
        "          plt.imshow(image_rgb)\n",
        "          plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "for i, index in enumerate(closest_indices):\n",
        "    image_path = os.path.join(folder_path, f\"{histogram_df.loc[index, 'id']}.jpg\")\n",
        "\n",
        "    # Load and display the image if it exists\n",
        "    if os.path.exists(image_path):\n",
        "        image = cv.imread(image_path)\n",
        "        if image is not None:\n",
        "            image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "            plt.subplot(1, 4, i + 1)\n",
        "            plt.imshow(image_rgb)\n",
        "            plt.axis('off')\n",
        "        else:\n",
        "            print(f\"Error loading image: {image_path}\")\n",
        "    else:\n",
        "        print(f\"Image file not found: {image_path}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UczsrdbGQwvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For all test images"
      ],
      "metadata": {
        "id": "9uEWDra5Tpa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_img_to_hist(image_path):\n",
        "  image = cv.imread(image_path)\n",
        "\n",
        "  hist_b = cv.calcHist([image], [channels[0]], None, [bins], hist_range)\n",
        "  hist_g = cv.calcHist([image], [channels[1]], None, [bins], hist_range)\n",
        "  hist_r = cv.calcHist([image], [channels[2]], None, [bins], hist_range)\n",
        "\n",
        "  hist_vector = np.concatenate((hist_b, hist_g, hist_r)).flatten()\n",
        "\n",
        "  return hist_vector"
      ],
      "metadata": {
        "id": "eZVCL8gcUULC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(filepath):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  if os.path.exists(filepath):\n",
        "        image = cv.imread(filepath)\n",
        "        if image is not None:\n",
        "            image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "            plt.subplot(1, 4, i + 1)\n",
        "            plt.imshow(image_rgb)\n",
        "            plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7wTr_0NoVu6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_indices(hist, metric):\n",
        "  closest_indices = find_closest_images(hist, histogram_df['histogram'], metric, num_images=4)\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  for i, index in enumerate(closest_indices):\n",
        "    image_path = os.path.join(folder_path, f\"{histogram_df.loc[index, 'id']}.jpg\")\n",
        "\n",
        "    # Load and display the image if it exists\n",
        "    if os.path.exists(image_path):\n",
        "        image = cv.imread(image_path)\n",
        "        if image is not None:\n",
        "            image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "            plt.subplot(1, 4, i + 1)\n",
        "            plt.imshow(image_rgb)\n",
        "            plt.axis('off')\n",
        "        else:\n",
        "            print(f\"Error loading image: {image_path}\")\n",
        "    else:\n",
        "        print(f\"Image file not found: {image_path}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d7VriaC0VGlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 1\n",
        "for image in test_images:\n",
        "  if counter == 6:\n",
        "    break\n",
        "\n",
        "  histogram = transform_img_to_hist(image)\n",
        "\n",
        "  plot_image(image)\n",
        "\n",
        "  plot_indices(histogram, 'euclidean')\n",
        "\n",
        "  counter+=1"
      ],
      "metadata": {
        "id": "oo4RoKEdTrmK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}